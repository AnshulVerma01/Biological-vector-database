{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Install python packages**"
      ],
      "metadata": {
        "id": "7rl4fY-u2uPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch sentence-transformers faiss-cpu numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqK79cM7Nmyj",
        "outputId": "3aaf3cc9-2600-49f4-ddc2-e7c59c48afbd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **vector_db.py**"
      ],
      "metadata": {
        "id": "zAhU6Umzncub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import os\n",
        "\n",
        "class VectorDatabase:\n",
        "    def __init__(self, model_name='all-mpnet-base-v2', storage_path='vector_db/'):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.storage_path = storage_path\n",
        "        self.embeddings = None\n",
        "        self.metadata = []\n",
        "        self.index = None\n",
        "\n",
        "        # Create storage directory if it does not exist\n",
        "        os.makedirs(self.storage_path, exist_ok=True)\n",
        "\n",
        "        # Try to load existing database if available\n",
        "        self.load()\n",
        "\n",
        "    def create(self, file_path, metadata=None):\n",
        "        \"\"\"Create an embedding for the text content of a file and add it to the database.\"\"\"\n",
        "        with open(file_path, 'r') as file:\n",
        "            text = file.read()\n",
        "\n",
        "        embedding = self.model.encode([text])[0]\n",
        "        self.metadata.append(metadata or {})\n",
        "        self._add_embedding(embedding)\n",
        "        self._save()  # Automatically save changes\n",
        "        print(f\"Entry created for file: {file_path}\")\n",
        "\n",
        "    def _add_embedding(self, embedding):\n",
        "        \"\"\"Add an embedding to the FAISS index.\"\"\"\n",
        "        if self.embeddings is None:\n",
        "            self.embeddings = np.array([embedding])\n",
        "            d = embedding.shape[0]\n",
        "            self.index = faiss.IndexFlatL2(d)\n",
        "        else:\n",
        "            self.embeddings = np.vstack((self.embeddings, embedding))\n",
        "\n",
        "        self.index.add(np.array([embedding]))\n",
        "\n",
        "    def read(self, query_file_path, top_k=5):\n",
        "        \"\"\"Search for similar entries in the database using the text content of a file.\"\"\"\n",
        "        if self.index is None:\n",
        "            print(\"No index found. Please load the database.\")\n",
        "            return\n",
        "\n",
        "        with open(query_file_path, 'r') as file:\n",
        "            query = file.read()\n",
        "\n",
        "        query_embedding = self.model.encode([query])[0]\n",
        "        distances, indices = self.index.search(np.array([query_embedding]), top_k)\n",
        "        results = [(self.metadata[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
        "        for result in results:\n",
        "            print(f\"Metadata: {result[0]}, Distance: {result[1]}\")\n",
        "\n",
        "    def update(self, text_id, new_file_path, new_metadata=None):\n",
        "        \"\"\"Update an existing text entry using the content from a new file.\"\"\"\n",
        "        if text_id >= len(self.metadata):\n",
        "            print(\"Invalid text ID.\")\n",
        "            return\n",
        "\n",
        "        with open(new_file_path, 'r') as file:\n",
        "            new_text = file.read()\n",
        "\n",
        "        # Recompute embedding for the updated text\n",
        "        new_embedding = self.model.encode([new_text])[0]\n",
        "        self.embeddings[text_id] = new_embedding\n",
        "        self.metadata[text_id] = new_metadata or {}\n",
        "\n",
        "        # Rebuild the FAISS index\n",
        "        self._rebuild_index()\n",
        "        self._save()  # Automatically save changes\n",
        "        print(f\"Entry {text_id} updated with file: {new_file_path}\")\n",
        "\n",
        "    def delete(self, text_id):\n",
        "        \"\"\"Delete an entry by its ID.\"\"\"\n",
        "        if text_id >= len(self.metadata):\n",
        "            print(\"Invalid text ID.\")\n",
        "            return\n",
        "\n",
        "        self.embeddings = np.delete(self.embeddings, text_id, axis=0)\n",
        "        del self.metadata[text_id]\n",
        "\n",
        "        # Rebuild the FAISS index\n",
        "        self._rebuild_index()\n",
        "        self._save()  # Automatically save changes\n",
        "        print(f\"Entry {text_id} deleted.\")\n",
        "\n",
        "    def _rebuild_index(self):\n",
        "        \"\"\"Rebuild the FAISS index after an update or delete operation.\"\"\"\n",
        "        if self.embeddings is not None and len(self.embeddings) > 0:\n",
        "            d = self.embeddings.shape[1]\n",
        "            self.index = faiss.IndexFlatL2(d)\n",
        "            self.index.add(self.embeddings)\n",
        "        else:\n",
        "            self.index = None\n",
        "\n",
        "    def _save(self):\n",
        "        \"\"\"Save embeddings, metadata, and index to disk.\"\"\"\n",
        "        if self.embeddings is not None:\n",
        "            np.save(os.path.join(self.storage_path, 'embeddings.npy'), self.embeddings)\n",
        "        with open(os.path.join(self.storage_path, 'metadata.json'), 'w') as f:\n",
        "            json.dump(self.metadata, f)\n",
        "        if self.index is not None:\n",
        "            faiss.write_index(self.index, os.path.join(self.storage_path, 'index.faiss'))\n",
        "        print(\"Database saved to disk.\")\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\"Load embeddings, metadata, and index from disk.\"\"\"\n",
        "        embeddings_path = os.path.join(self.storage_path, 'embeddings.npy')\n",
        "        metadata_path = os.path.join(self.storage_path, 'metadata.json')\n",
        "        index_path = os.path.join(self.storage_path, 'index.faiss')\n",
        "\n",
        "        if os.path.exists(embeddings_path):\n",
        "            self.embeddings = np.load(embeddings_path)\n",
        "        else:\n",
        "            self.embeddings = None\n",
        "\n",
        "        if os.path.exists(metadata_path):\n",
        "            with open(metadata_path, 'r') as f:\n",
        "                self.metadata = json.load(f)\n",
        "        else:\n",
        "            self.metadata = []\n",
        "\n",
        "        if os.path.exists(index_path):\n",
        "            self.index = faiss.read_index(index_path)\n",
        "        else:\n",
        "            self.index = None\n",
        "\n",
        "        print(\"Database loaded from disk.\")\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description='Vector Database CLI')\n",
        "    subparsers = parser.add_subparsers(dest='command')\n",
        "\n",
        "    # Subparser for 'create'\n",
        "    parser_create = subparsers.add_parser('create', help='Create a new entry from a text file')\n",
        "    parser_create.add_argument('file_path', type=str, help='Path to the text file')\n",
        "    parser_create.add_argument('--metadata', type=json.loads, default='{}', help='Metadata as JSON')\n",
        "\n",
        "    # Subparser for 'read'\n",
        "    parser_read = subparsers.add_parser('read', help='Read/search entries using a query file')\n",
        "    parser_read.add_argument('query_file_path', type=str, help='Path to the query text file')\n",
        "    parser_read.add_argument('--top_k', type=int, default=5, help='Number of top results to return')\n",
        "\n",
        "    # Subparser for 'update'\n",
        "    parser_update = subparsers.add_parser('update', help='Update an existing entry using a new text file')\n",
        "    parser_update.add_argument('text_id', type=int, help='ID of the text to update')\n",
        "    parser_update.add_argument('new_file_path', type=str, help='Path to the new text file')\n",
        "    parser_update.add_argument('--new_metadata', type=json.loads, default='{}', help='Updated metadata as JSON')\n",
        "\n",
        "    # Subparser for 'delete'\n",
        "    parser_delete = subparsers.add_parser('delete', help='Delete an entry')\n",
        "    parser_delete.add_argument('text_id', type=int, help='ID of the text to delete')\n",
        "\n",
        "    # Subparser for 'load'\n",
        "    parser_load = subparsers.add_parser('load', help='Load the database from disk')\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "    db = VectorDatabase()\n",
        "\n",
        "    if args.command == 'create':\n",
        "        db.create(args.file_path, args.metadata)\n",
        "    elif args.command == 'read':\n",
        "        db.read(args.query_file_path, args.top_k)\n",
        "    elif args.command == 'update':\n",
        "        db.update(args.text_id, args.new_file_path, args.new_metadata)\n",
        "    elif args.command == 'delete':\n",
        "        db.delete(args.text_id)\n",
        "    elif args.command == 'load':\n",
        "        db.load()\n",
        "    else:\n",
        "        print(\"Unknown command\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "BwGTEY84naoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create database**"
      ],
      "metadata": {
        "id": "kZcsFsVLnls0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python vector_db.py create /content/cartoon.txt --metadata '{\"Topic\": \"Cartoon\"}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVHGSJs44uJo",
        "outputId": "a3a345d5-005f-42ec-ec96-6ad4cc9e7f1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-21 10:42:33.448876: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-21 10:42:33.472384: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-21 10:42:33.479287: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-21 10:42:33.495751: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-21 10:42:35.031867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Database loaded from disk.\n",
            "Database saved to disk.\n",
            "Entry created for file: /content/cartoon.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python vector_db.py create /content/dl.txt --metadata '{\"Topic\": \"Deep learning\"}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peBnxiKRSDJX",
        "outputId": "9e920398-9922-4b21-99c6-1a8fd153d413"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-21 10:42:49.572240: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-21 10:42:49.595513: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-21 10:42:49.602399: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-21 10:42:49.619611: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-21 10:42:51.119627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Database loaded from disk.\n",
            "Database saved to disk.\n",
            "Entry created for file: /content/dl.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python vector_db.py create /content/ml.txt --metadata '{\"Topic\": \"Machine learning\"}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6A3GYr1X8D3",
        "outputId": "82352877-d407-4da1-ea41-4bd6bf27ae63"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-21 10:43:02.145955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-21 10:43:02.169557: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-21 10:43:02.176506: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-21 10:43:02.192583: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-21 10:43:03.676717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Database loaded from disk.\n",
            "Database saved to disk.\n",
            "Entry created for file: /content/ml.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Read database or search for query**"
      ],
      "metadata": {
        "id": "xcvK8avfnvfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python vector_db.py read /content/query.txt --top_k 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEUfhVJ3Mdlp",
        "outputId": "3f823f58-5288-4d56-99f6-a74441a92b46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-21 10:43:41.109750: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-21 10:43:41.148479: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-21 10:43:41.160380: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-21 10:43:41.186962: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-21 10:43:43.357050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Database loaded from disk.\n",
            "Metadata: {'Topic': 'Machine learning'}, Distance: 0.6173807382583618\n",
            "Metadata: {'Topic': 'Deep learning'}, Distance: 0.886598527431488\n",
            "Metadata: {'Topic': 'Cartoon'}, Distance: 2.050119400024414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Update entry**"
      ],
      "metadata": {
        "id": "-9zXBv88nzNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python vector_db.py update 3 --new_metadata '{\"Topic\": \"Query\"}' /content/query.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsKND4dPNdXl",
        "outputId": "31bdbff5-017d-4214-d68c-80e5c10618a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-21 10:44:28.058506: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-21 10:44:28.081519: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-21 10:44:28.088440: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-21 10:44:28.104798: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-21 10:44:29.902800: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Database loaded from disk.\n",
            "Database saved to disk.\n",
            "Entry 3 updated with file: /content/query.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Delete entry**"
      ],
      "metadata": {
        "id": "vL88u3RNn1_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python vector_db.py delete 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBnL_CquWdNh",
        "outputId": "d2903fa3-7a5c-45e9-e683-41eae3fd112e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-21 10:44:48.588306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-21 10:44:48.611945: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-21 10:44:48.618851: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-21 10:44:48.636146: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-21 10:44:50.156660: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Database loaded from disk.\n",
            "Database saved to disk.\n",
            "Entry 3 deleted.\n"
          ]
        }
      ]
    }
  ]
}